





import pandas as pd
import matplotlib.pyplot as plt
import ast
import re
import numpy as np











plot_summaries_df = pd.read_csv("data/CMU/plot_summaries.txt", delimiter="\t", names = ["Wikipedia_movie_ID", "Plot Summaries"])

print(f"The plot summaries dataframe has {len(plot_summaries_df):,} values.")
plot_summaries_df.head()


movie_metadata_df = pd.read_csv("data/CMU/movie.metadata.tsv", delimiter='\t', names = ["Wikipedia_movie_ID","Freebase_movie_ID","Movie_name","Movie_release_date","Movie_box_office_revenue","Movie_runtime","Movie_languages","Movie_countries","Movie_genres"])
print(f"The movie metadata dataframe has {len(movie_metadata_df):,} values.")
movie_metadata_df.head()


movie_metadata_df["Movie_name"] = (movie_metadata_df["Movie_name"]
                    .str.strip()  #Remove leading/trailing whitespace
                    .str.lower()  #Convert to lowercase
                    .replace("", np.nan)  #Replace empty strings with NaN
                   )


#Movie languages, countries, and genres are formatted as a dictionary, but they are actually a string. We convert them to a list.
movie_metadata_df["Movie_languages"] = movie_metadata_df["Movie_languages"].apply(ast.literal_eval)
movie_metadata_df["Movie_languages"] = movie_metadata_df["Movie_languages"].apply(lambda x: list(x.values()))

movie_metadata_df["Movie_countries"] = movie_metadata_df["Movie_countries"].apply(ast.literal_eval)
movie_metadata_df["Movie_countries"] = movie_metadata_df["Movie_countries"].apply(lambda x: list(x.values()))

movie_metadata_df["Movie_genres"] = movie_metadata_df["Movie_genres"].apply(ast.literal_eval)
movie_metadata_df["Movie_genres"] = movie_metadata_df["Movie_genres"].apply(lambda x: list(x.values()))


#Cleaning
def clean_string_list(lst):
    return [s.strip().lower() if isinstance(s, str) and s.strip() != "" else np.nan for s in lst]

movie_metadata_df["Movie_languages"] = movie_metadata_df["Movie_languages"].apply(clean_string_list)
movie_metadata_df["Movie_countries"] = movie_metadata_df["Movie_countries"].apply(clean_string_list)
movie_metadata_df["Movie_genres"] = movie_metadata_df["Movie_genres"].apply(clean_string_list)


movie_metadata_df.head()


#There are inconsistencies in the date format: some rows have the date as year only, others as year-month, and some as year-month-day. We convert them all to the year format only since the month and day are not relevant to our analysis.
full_date_pattern = r'^\d{4}-\d{2}-\d{2}$' #Matches YYYY-MM-DD
year_month_pattern = r'^\d{4}-\d{2}$' #Matches YYYY-MM
year_only_pattern = r'^\d{4}$' #Matches YYYY

def identify_pattern(date):
    if pd.isna(date):
        return "Missing"
    elif re.match(full_date_pattern, date):
        return "Full Date (YYYY-MM-DD)"
    elif re.match(year_month_pattern, date):
        return "Year & Month Date (YYYY-MM)"
    elif re.match(year_only_pattern, date):
        return "Year Only (YYYY)"
    else:
        return "Other"

movie_metadata_df["Pattern"] = movie_metadata_df["Movie_release_date"].apply(identify_pattern)
pattern_summary = movie_metadata_df.groupby("Pattern").size().reset_index(name="Count")

print("Pattern Summary:")
print(pattern_summary)


movie_metadata_df["Movie_release_date"] = movie_metadata_df["Movie_release_date"].apply(lambda x: str(x)[:4] if pd.notnull(x) else None)
movie_metadata_df = movie_metadata_df.drop(columns=["Pattern"])


n_null_movie_metadata = ((movie_metadata_df.isnull().sum() / len(movie_metadata_df)) * 100).apply(lambda x: f"{x:,.2f}%")

print(
    f"Percentage of null values per column:\n"
    f"movie_metadata_df:\n{n_null_movie_metadata}"
)


movie_metadata_df.head()


CMU_movies = pd.read_csv("./data/CMU/filtered_movie_metadata.csv", delimiter=",", skipinitialspace=True)

# If there's an extra unnamed column, drop it
if "Unnamed: 0" in CMU_movies.columns:
    CMU_movies = CMU_movies.drop(columns=["Unnamed: 0"])
CMU_movies.columns = [
    "Wikipedia_movie_ID",
    "Freebase_movie_ID",
    "Movie_name",
    "Movie_release_date",
    "Movie_box_office_revenue",
    "runtimeMinutes",
    "Movie_languages",
    "Movie_countries",
    "genres",
    "Cast",
    "Female_actors",
    "Male_actors",
    "Female_actor_percentage",
    "Average_female_actor_age",
    "Average_male_actor_age"
]
CMU_movies.head()








# Loading the datasets. Null values are represented using "\N".
IMDB_ratings_df = pd.read_csv("data/IMDB/title.ratings.tsv", delimiter="\t", na_values="\\N")
IMDB_basics_df = pd.read_csv("data/IMDB/title.basics.tsv", delimiter="\t", na_values="\\N", low_memory=False)
IMDB_crew_df = pd.read_csv("data/IMDB/title.crew.tsv", delimiter="\t", na_values="\\N", low_memory=False)


IMDB_ratings_df.head()


IMDB_basics_df.head()


IMDB_crew_df.head()


# Checking the lengths of the datasets
print(f"Length of IMDB_ratings_df: {len(IMDB_ratings_df):,}\n"
      f"Length of IMDB_basics_df: {len(IMDB_basics_df):,}\n"
      f"Length of IMDB_crew_df: {len(IMDB_crew_df):,}")





# Merging all three datasets.
IMDB_merged_df = pd.merge(IMDB_ratings_df, IMDB_basics_df, how="inner", left_on="tconst", right_on="tconst")
IMDB_merged_df = pd.merge(IMDB_merged_df, IMDB_crew_df, how="inner", on="tconst")

print(f"The resulting merged dataframe has length: {len(IMDB_merged_df):,}.")
print(f"{len(IMDB_ratings_df)-len(IMDB_merged_df):,} rows were lost in the merging process.")
IMDB_merged_df.head()








# Filtering movies from the list of titles.
IMDB_merged_df = IMDB_merged_df[IMDB_merged_df["titleType"] == "movie"]

print(f"There are {len(IMDB_merged_df):,} movies in the resulting dataframe.")
IMDB_merged_df.head()





# Checking the percentage of null values in the dataset.
n_null_IMDB = ((IMDB_merged_df.isnull().sum() / len(IMDB_merged_df)) * 100).apply(lambda x: f"{x:,.2f}%")

print(
    f"Percentage of null values per column:\n"
    f"IMDB_ratings_df:\n{n_null_IMDB}"
)





# Dropping unnecessary columns.
IMDB_merged_df = IMDB_merged_df.drop(columns=["endYear", "titleType"], axis=1)

print(f"The resulting dataframe has {len(IMDB_merged_df):,} rows.")
IMDB_merged_df.head()











# Merging on the original title.
merge1 = pd.merge(IMDB_merged_df, CMU_movies, how="inner", left_on="originalTitle", right_on="Movie_name")
# Merging on the secondary title.
merge2 = pd.merge(IMDB_merged_df, CMU_movies, how="inner", left_on="primaryTitle", right_on="Movie_name")

# Concatenating and dropping duplicates that appear from movies with the same originalTitle and primaryTitle.
movie_df = pd.concat([merge1, merge2]).drop_duplicates().reset_index(drop=True)

print(f"The resulting dataframe has {len(movie_df):,} rows.")
movie_df.head()





n_null_movie = (movie_df.isnull().sum()/len(movie_df)).apply(lambda x:f"{x:.2%}")

print(f"Percentage of null values per column:\n{n_null_movie}")





# Combining all non-null values from runtimeMinutes_x and runtimeMinutes_y into runtimeMinutes.
movie_df["runtimeMinutes"] = movie_df["runtimeMinutes_x"].combine_first(movie_df["runtimeMinutes_y"])

# Dropping the unnecessary columns.
movie_df.drop(columns=["runtimeMinutes_x", "runtimeMinutes_y", "genres_x"], inplace=True)

# Renaming the column to Genres.
movie_df.rename(columns={"genres_y":"Genres"}, inplace=True)
movie_df.head()





test1 = movie_df["Movie_name"] == movie_df["primaryTitle"]  
test2 = movie_df["Movie_name"] == movie_df["originalTitle"]

# Checking if there are any movies for which Movie_name is not either in primaryTitle or originalTitle
print(f"There are {(~(test1 | test2)).sum().item()} movies for which Movie_name is in neither primaryTitle ot originalTitle.")





movie_df.drop(columns="Movie_name", inplace=True)





movie_df = pd.merge(movie_df, plot_summaries_df, how="left", on="Wikipedia_movie_ID")

# Checking how many movies have plot summaries
n_movie_plots = (1 - (movie_df["Plot Summaries"].isnull().sum() / len(movie_df))) * len(movie_df)
print(f"{int(n_movie_plots):,} movies from our final dataset have plot summaries.")





movie_df.drop(columns=["Wikipedia_movie_ID", "tconst", "Freebase_movie_ID"], inplace=True)





movie_df.head()















